{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Asus\\\\Machine_learning\\\\LLM\\\\Projects\\\\BIRD_benchmark_SQL\\\\notebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Asus\\\\Machine_learning\\\\LLM\\\\Projects\\\\BIRD_benchmark_SQL'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "from Bird_bench_SQL import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DataSplittingConfig:\n",
    "    data_file_path  : Path\n",
    "    train_file_path : Path\n",
    "    test_file_path  : Path \n",
    "    db_id_name      : str \n",
    "    train_size      : int\n",
    "    test_size       : int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bird_bench_SQL.constants import *\n",
    "from Bird_bench_SQL.utils.common import read_yaml,create_directories\n",
    "from Bird_bench_SQL.config.configuration import ConfigurationManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_filepath    = CONFIG_FILE_PATH,\n",
    "                 params_filepath    = PARAMS_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_splitting_config(self) -> DataSplittingConfig:\n",
    "        config =  self.config.data_splitting\n",
    "        params = self.params \n",
    "        logger.info('Data preprocessing initialized')\n",
    "        data_procesing_config = DataSplittingConfig(data_file_path     = config.data_file_path,\n",
    "                                                     train_file_path    = config.train_file_path,\n",
    "                                                     test_file_path     = config.test_file_path,\n",
    "                                                     db_id_name         = params.db_id,\n",
    "                                                     train_size         = params.TRAIN_SIZE,\n",
    "                                                     test_size          = params.TEST_SIZE) \n",
    "        return data_procesing_config        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-09 15:35:08,791: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-09-09 15:35:08,797: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-09-09 15:35:08,798: INFO: common: created directory at: artifacts]\n",
      "[2024-09-09 15:35:08,798: INFO: 459710641: Data preprocessing initialized]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "manager = ConfigurationManager()\n",
    "path = manager.get_data_splitting_config()\n",
    "file_path = path.data_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bird_bench_SQL.utils.common import load_json,save_json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSplitting:\n",
    "\n",
    "    def __init__(self,config = DataSplittingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def data_splitting(self):\n",
    "\n",
    "        if not os.path.exists(self.config.train_file_path):\n",
    "            data_file       = self.config.data_file_path\n",
    "            logger.info(f\"Data splitting has started\")\n",
    "            data_file       = load_json(data_file)\n",
    "            logger.info(f\"{data_file} has loaded succesfully completed\")\n",
    "            specific_data   = []\n",
    "            for data in data_file:\n",
    "                if data['db_id'] == self.config.db_id_name:\n",
    "                    specific_data.append(data)\n",
    "            random.seed(42)\n",
    "            random.shuffle(specific_data)\n",
    "            total_size  = len(specific_data) \n",
    "            train_size  = int(0.7 * total_size)\n",
    "\n",
    "            logger.info(f\"{data_file} has loaded for data spiting\")\n",
    "            train_data  = specific_data[:train_size]\n",
    "            test_data   = specific_data[train_size:]\n",
    "            logger.info(f\"{data_file} - data spiting completed\")\n",
    "\n",
    "            save_json(path  = self.config.train_file_path,\n",
    "                      data  = train_data)\n",
    "            save_json(path  = self.config.test_file_path,\n",
    "                      data  = test_data)\n",
    "            logger.info(\"data splitting completed\")\n",
    "        else:\n",
    "            logger.info(f\"{self.config.data_file_path} file is already present\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-09 15:35:16,011: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-09-09 15:35:16,014: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-09-09 15:35:16,016: INFO: common: created directory at: artifacts]\n",
      "[2024-09-09 15:35:16,016: INFO: 459710641: Data preprocessing initialized]\n",
      "[2024-09-09 15:35:16,017: INFO: 3539417964: artifacts/data/train.json file is already present]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config                  = ConfigurationManager()\n",
    "    data_splitting_config  = config.get_data_splitting_config()\n",
    "    data_splitting          = DataSplitting(config=data_splitting_config)\n",
    "    data_splitting.data_splitting()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
