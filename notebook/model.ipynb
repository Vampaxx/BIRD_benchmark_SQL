{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "sql_file = Path(\"datas\\train_gold.sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('datas\\\\train.json', 'r') as file:\n",
    "    text_sql_data = json.load(file)\n",
    "\n",
    "\n",
    "movie_4_data = []\n",
    "for movie_4 in text_sql_data:\n",
    "  if movie_4['db_id'] == \"movies_4\":\n",
    "    movie_4_data.append(movie_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "#MODEL_NAME = \"llama3-8b-8192\"\n",
    "MODEL_NAME = \"llama3-70b-8192\"\n",
    "#MODEL_NAME  = \"mixtral-8x7b-32768\"\n",
    "\n",
    "llm = ChatGroq(model        = MODEL_NAME,\n",
    "               temperature  = 0,\n",
    "               api_key      = GROQ_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 110\n",
      "Validation size: 31\n",
      "Test size: 17\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42) \n",
    "random.shuffle(movie_4_data)\n",
    "\n",
    "# Calculate the split indices\n",
    "total_size  = len(movie_4_data)\n",
    "train_size  = int(0.7 * total_size)\n",
    "val_size    = int(0.2 * total_size)\n",
    "\n",
    "# Split the data\n",
    "train_data  = movie_4_data[:train_size]\n",
    "val_data    = movie_4_data[train_size:train_size + val_size]\n",
    "test_data   = movie_4_data[train_size + val_size:]\n",
    "\n",
    "# Results\n",
    "print(f\"Train size: {len(train_data)}\")\n",
    "print(f\"Validation size: {len(val_data)}\")\n",
    "print(f\"Test size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 110\n",
      "Test size: 48\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42) \n",
    "random.shuffle(movie_4_data)\n",
    "\n",
    "# Calculate the split indices\n",
    "total_size  = len(movie_4_data)\n",
    "train_size  = int(0.7 * total_size)\n",
    "\n",
    "# Split the data\n",
    "train_data  = movie_4_data[:train_size]\n",
    "test_data   = movie_4_data[train_size:]\n",
    "\n",
    "# Results\n",
    "print(f\"Train size: {len(train_data)}\")\n",
    "print(f\"Test size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batabase connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "sqlite_file_path = \"datas\\\\movies_4.sqlite\"\n",
    "\n",
    "conn    = sqlite3.connect(sqlite_file_path)\n",
    "cursor  = conn.cursor()\n",
    "\n",
    "copy_train_data = train_data.copy()\n",
    "\n",
    "for data in copy_train_data:\n",
    "  query = data['SQL']\n",
    "  cursor.execute(query)\n",
    "\n",
    "  results = cursor.fetchall()\n",
    "  data[\"Answer\"] = \",\".join([str(ans[0]) for ans in results])\n",
    "\n",
    "conn.close()\n",
    "\n",
    "\n",
    "\n",
    "conn  = create_engine(f\"sqlite:///{sqlite_file_path}\")\n",
    "db    = SQLDatabase(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternating the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_data = []\n",
    "\n",
    "for item in copy_train_data:\n",
    "    new_item = {\n",
    "        \"Question\"  : f\"{item['question']}==>> {item['evidence']}\",\n",
    "        \"SQLQuery\"  : item['SQL'],\n",
    "        \"SQLResult\" : \"Result of the SQL query\",  # Placeholder for the actual SQL result if needed\n",
    "        \"Answer\"    : item['Answer']\n",
    "    }\n",
    "    SQL_data.append(new_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few_shot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "few_shots = random.sample(SQL_data,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Semantic Similarity Based example selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_45440\\1261799606.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embeddings    = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
      "c:\\Users\\Asus\\anaconda3\\envs\\llm_env\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\Asus\\anaconda3\\envs\\llm_env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus\\anaconda3\\envs\\llm_env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import SemanticSimilarityExampleSelector\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "\n",
    "embeddings    = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "to_vectorize  = [' '.join(sent.values()) for sent in few_shots]                                   #[' '.join([str(item) for value in data.values() for item in (value if isinstance(value, list) else [value])])for data in few_shots]\n",
    "vectorstore   = Chroma.from_texts(to_vectorize,embeddings,metadatas=few_shots)\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector(vectorstore  = vectorstore,k= 2,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Answer': \"City of Angels,It's a Wonderful Life,Dogma,The Prophecy,Frailty,Legion,The Mortal Instruments: City of Bones,The Christmas Candle\",\n",
       "  'Question': 'Look for the movie title with the keyword of \"angel\".==>> keyword of \"angel\" refers to keyword_name = \\'angel\\'',\n",
       "  'SQLQuery': \"SELECT T1.title FROM movie AS T1 INNER JOIN movie_keywords AS T2 ON T1.movie_id = T2.movie_id INNER JOIN keyword AS T3 ON T2.keyword_id = T3.keyword_id WHERE T3.keyword_name = 'angel'\",\n",
       "  'SQLResult': 'Result of the SQL query'},\n",
       " {'Answer': 'Iron Man 3',\n",
       "  'Question': \"Which movie has the keyword 'extremis?'==>> Which movie refers to title; keyword 'extremis' refers to keyword_name = 'extremis'\",\n",
       "  'SQLQuery': \"SELECT T1.title FROM movie AS T1 INNER JOIN movie_keywords AS T2 ON T1.movie_id = T2.movie_id INNER JOIN keyword AS T3 ON T2.keyword_id = T3.keyword_id WHERE T3.keyword_name = 'extremis'\",\n",
       "  'SQLResult': 'Result of the SQL query'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_selector.select_examples({'question': 'What keyword can the user use to search for the movie Finding Nemo?',})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate\n",
    "from langchain.chains.sql_database.prompt import PROMPT_SUFFIX\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_experimental.sql import SQLDatabaseChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQLite_prompt = \"\"\"\n",
    "You are a SQLite expert. Given an input question , first create a syntactically correct SQLite query (standard sql query and do not include any extra symbals) to run,\n",
    "then look at the results of the query and return the answer only. \n",
    "If relevant evidence is provided, use it to infer additional conditions or filters in the query.\n",
    "For example, if the evidence states \"The condition of the loans requires the account type should be the owner,\" you can infer the condition \"account.type = 'OWNER'\" in the query.\n",
    "\n",
    "Unless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per SQLite.\n",
    "You can order the results to return the most informative data in the database.\n",
    "Never query for all columns from a table. You must query only the columns that are needed to answer the question.\n",
    "Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
    "\n",
    "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist.Only use the column names listed in the tables below.\n",
    "Also, pay attention to which column is in which table.\n",
    "\n",
    "\n",
    "If the question involves \"today,\" use the `date('now')` function to get the current date.\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: Question here\n",
    "SQLQuery: SQL Query to run \n",
    "SQLResult: Result of the SQLQuery\n",
    "Answer: Final answer here\n",
    "\n",
    "\n",
    "Only respond in JSON format, dont include anything other than json in output.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(with evidence provided after the question, ending with ==>>)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"(with evidence provided after the question, ending with ==>>)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables =['Question','SQLQuery','SQLResult','Answer',],\n",
    "    template        ='\\nQuestion: {Question}\\nSQLQuery: {SQLQuery}\\nSQLResult: {SQLResult}\\nAnswer: {Answer}',\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(example_selector= example_selector,\n",
    "                                        example_prompt  = example_prompt,\n",
    "                                        prefix          = SQLite_prompt,\n",
    "                                        suffix          = PROMPT_SUFFIX,\n",
    "                                        input_variables=['input', 'table_info', 'top_k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Only use the following tables:\\n{table_info}\\n\\nQuestion: {input}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT_SUFFIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_sql_query_chain\n",
    "new_chain = create_sql_query_chain(llm=llm,db=db,prompt=few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques = {'question': \"When was the release date of the latest movie in which Dariusz Wolski worked as a crew member? ==>> release date of the latest movie refers to max(release_date)\" }\n",
    "ques_1 = {\"question\":\n",
    "         \"What is the average revenue of the movie in which Dariusz Wolski works as the director of photography? ==>> director of photography refers to job = 'Director of Photography'; average revenue = divide(sum(revenue), count(movie_id))\" }\n",
    "ques_2 = {'question': 'Provide the release date and language of the most popular movie.==>> language refers to langauge_name; most popular movie refers to max(popularity)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\"Question\": \"Provide the release date and language of the most popular movie.\",\\n\"SQLQuery\": \"SELECT T1.release_date, T3.language_name FROM movie AS T1 INNER JOIN movie_languages AS T2 ON T1.movie_id = T2.movie_id INNER JOIN language AS T3 ON T2.language_id = T3.language_id ORDER BY T1.popularity DESC LIMIT 1\",\\n\"SQLResult\": \"Result of the SQL query\",\\n\"Answer\": \"2003-05-30, English\"\\n}'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chain.invoke(ques_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"Question\": \"Provide the release date and language of the most popular movie.\",\n",
      "\"SQLQuery\": \"SELECT T1.release_date, T3.language_name FROM movie AS T1 INNER JOIN movie_languages AS T2 ON T1.movie_id = T2.movie_id INNER JOIN language AS T3 ON T2.language_id = T3.language_id ORDER BY T1.popularity DESC LIMIT 1\",\n",
      "\"SQLResult\": \"Result of the SQL query\",\n",
      "\"Answer\": \"2003-05-30, English\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "output = new_chain.invoke(ques_2) \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\"Question\": \"Provide the release date and language of the most popular movie.\",\\n\"SQLQuery\": \"SELECT T1.release_date, T3.language_name FROM movie AS T1 INNER JOIN movie_languages AS T2 ON T1.movie_id = T2.movie_id INNER JOIN language AS T3 ON T2.language_id = T3.language_id ORDER BY T1.popularity DESC LIMIT 1\",\\n\"SQLResult\": \"Result of the SQL query\",\\n\"Answer\": \"2003-05-30, English\"\\n}'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Question': 'Provide the release date and language of the most popular movie.',\n",
       " 'SQLQuery': 'SELECT T1.release_date, T3.language_name FROM movie AS T1 INNER JOIN movie_languages AS T2 ON T1.movie_id = T2.movie_id INNER JOIN language AS T3 ON T2.language_id = T3.language_id ORDER BY T1.popularity DESC LIMIT 1',\n",
       " 'SQLResult': 'Result of the SQL query',\n",
       " 'Answer': '2003-05-30, English'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = json.loads(output)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT T1.release_date, T3.language_name FROM movie AS T1 INNER JOIN movie_languages AS T2 ON T1.movie_id = T2.movie_id INNER JOIN language AS T3 ON T2.language_id = T3.language_id ORDER BY T1.popularity DESC LIMIT 1'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#qu = output.split(\"\\n\\n\")[1].split(\"SQLQuery:\")[-1]\n",
    "qu =output['SQLQuery']\n",
    "qu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('2015-09-30',)]\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(val_data[15]['SQL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('2015-06-17', 'English')]\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(qu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'db_id': 'movies_4',\n",
       " 'question': 'What keyword can the user use to search for the movie Finding Nemo?',\n",
       " 'evidence': \"What keyword refers to keyword_name; Finding Nemo refers to title = 'Finding Nemo'\",\n",
       " 'SQL': \"SELECT T3.keyword_name FROM movie AS T1 INNER JOIN movie_keywords AS T2 ON T1.movie_id = T2.movie_id INNER JOIN keyword AS T3 ON T2.keyword_id = T3.keyword_id WHERE T1.title = 'Finding Nemo'\"}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'db_id': 'movies_4',\n",
       " 'question': 'Provide the release date and language of the most popular movie.',\n",
       " 'evidence': 'language refers to langauge_name; most popular movie refers to max(popularity)',\n",
       " 'SQL': 'SELECT T1.release_date, T3.language_name FROM movie AS T1 INNER JOIN movie_languages AS T2 ON T1.movie_id = T2.movie_id INNER JOIN language AS T3 ON T2.language_id = T3.language_id ORDER BY T1.popularity DESC LIMIT 1',\n",
       " 'Answer': '2015-06-17'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[19]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
